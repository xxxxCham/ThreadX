# üéØ Rapport Interm√©diaire - D√©bogage Token Gestion

**Date**: 10 octobre 2025  
**Dur√©e**: 30 minutes  
**Fichiers trait√©s**: 2 (token_diversity.py cr√©√©, diversity_pipeline.py en cours)

---

## ‚úÖ Progr√®s R√©alis√©s

### 1. Cr√©ation token_diversity.py ‚úÖ

**Fichier**: `src/threadx/data/providers/token_diversity.py` (316 lignes)

**Classes impl√©ment√©es**:
- ‚úÖ `TokenDiversityConfig` - Configuration des groupes/symboles
- ‚úÖ `TokenDiversityDataSource` - Provider OHLCV brut
- ‚úÖ `create_default_config()` - Configuration par d√©faut

**√âtat**: **COMPLET** avec impl√©mentation stub

**D√©tails**:
```python
# Classes principales
class TokenDiversityConfig:
    groups: Mapping[str, List[str]]
    symbols: List[str]
    supported_tf: Tuple[str, ...]

class TokenDiversityDataSource:
    def __init__(self, config: TokenDiversityConfig)
    def list_symbols(self, group: Optional[str] = None) -> List[str]
    def list_groups(self) -> List[str]
    def fetch_ohlcv(...) -> pd.DataFrame  # STUB - √Ä impl√©menter
    def validate_symbol(self, symbol: str) -> bool
    def validate_timeframe(self, timeframe: str) -> bool

def create_default_config() -> TokenDiversityConfig:
    # Groupes: L1, DeFi, L2, Stable
```

**Note**: `fetch_ohlcv()` est un **STUB** qui l√®ve `NotImplementedError`. 
N√©cessite impl√©mentation pour:
- Lecture depuis fichiers Parquet locaux, OU
- API Binance/exchange, OU
- Int√©gration TradXProManager

---

### 2. Corrections diversity_pipeline.py (Partielles) üîÑ

**Fichier**: `src/threadx/data/diversity_pipeline.py` (417 lignes)

**Corrections appliqu√©es**:
- ‚úÖ Supprim√© `Tuple` inutilis√© (ligne 14)
- ‚úÖ Supprim√© `normalize_ohlcv` inutilis√© (ligne 19)
- ‚úÖ Supprim√© `read_frame` inutilis√© (ligne 19)
- ‚úÖ Supprim√© import `RegistryManager` (ligne 25 - n'existe pas)
- ‚úÖ Corrig√© `provider.get_frame()` ‚Üí `provider.fetch_ohlcv()` (ligne 137)

**Corrections restantes**:
- ‚ùå `bank.compute_batch()` n'existe pas (ligne 170)
- ‚ùå `td_config.cache_dir` n'existe pas (ligne 197)  
- ‚ùå `provider.list_symbols(limit=10)` - param√®tre invalide (ligne 256)
- ‚ùå Type `List[int]` devrait √™tre `List[float]` (ligne 329)
- ‚ö†Ô∏è 15 lignes >79 chars (formatage)

---

## ‚ùå Probl√®mes Bloquants Restants

### 1. API IndicatorBank Incompatible üö®

**Ligne 170-172**:
```python
# Code actuel (INVALIDE)
indicators_result = bank.compute_batch(
    data=ohlcv_df, indicators=indicators, symbol=symbol
)
```

**Probl√®me**: `IndicatorBank.compute_batch()` **n'existe pas**

**API r√©elle disponible**:
```python
# bank.py ligne 499
def batch_ensure(
    self,
    indicator_type: str,        # ‚ùå Pas "indicators" list
    params_list: List[Dict],    # ‚ùå Params structur√©s
    data: DataFrame,
    symbol: str = "",
    timeframe: str = ""
) -> Dict[str, result]
```

**Diff√©rence**:
- `compute_batch()` attendrait une liste d'indicateurs (ex: `["rsi_14", "bb_20"]`)
- `batch_ensure()` attend un type unique + liste de param√®tres

**Solutions possibles**:

#### Option A : Adapter diversity_pipeline.py √† l'API batch_ensure
```python
# Transformer indicators=["rsi_14", "bb_20", "sma_50"]
# En:
results = {}
for indicator in indicators:
    ind_type, params = parse_indicator(indicator)  # ex: "rsi_14" ‚Üí ("rsi", {period: 14})
    result = bank.batch_ensure(ind_type, [params], ohlcv_df, symbol)
    results.update(result)
```

#### Option B : Cr√©er m√©thode wrapper compute_batch() dans IndicatorBank
```python
# Dans bank.py
def compute_batch(
    self,
    data: DataFrame,
    indicators: List[str],  # ex: ["rsi_14", "bb_20_2.0"]
    symbol: str = ""
) -> DataFrame:
    """
    Wrapper pour calculer plusieurs indicateurs d'un coup.
    
    Args:
        indicators: Liste format "type_param1_param2" 
                    ex: "rsi_14", "bb_20_2.0", "sma_50"
    
    Returns:
        DataFrame avec colonnes d'indicateurs ajout√©es
    """
    # Impl√©menter parsing + appels batch_ensure
    ...
```

#### Option C : Utiliser ensure() individuel
```python
# Plus simple mais moins performant
for indicator in indicators:
    ind_spec = parse_indicator_spec(indicator)
    result = bank.ensure(ind_spec, data, symbol)
    # Ajouter au DataFrame
```

**Recommandation**: **Option B** (cr√©er `compute_batch()` wrapper)
- Conserve l'intention du code original
- API plus intuitive pour les utilisateurs
- Performance raisonnable via batch_ensure interne

---

### 2. Configuration cache_dir Manquante üö®

**Ligne 197**:
```python
output_dir or td_config.cache_dir,  # ‚ùå cache_dir n'existe pas
```

**Probl√®me**: `TokenDiversityConfig` n'a pas d'attribut `cache_dir`

**Solution simple**:
```python
# Option 1: Ajouter cache_dir √† TokenDiversityConfig
@dataclass(frozen=True)
class TokenDiversityConfig:
    groups: Mapping[str, List[str]]
    symbols: List[str]
    supported_tf: Tuple[str, ...] = ("1m", "5m", "15m", "1h", "4h", "1d")
    cache_dir: str = "./data/cache"  # ‚úÖ Ajout√©

# Option 2: Utiliser valeur par d√©faut dans diversity_pipeline.py
output_dir or Path("./data/diversity_cache")  # ‚úÖ Fallback
```

**Recommandation**: **Option 1** (ajouter √† Config)
- Plus coh√©rent avec la configuration centralis√©e
- Permet override par utilisateur

---

### 3. Param√®tre list_symbols(limit=...) Invalide üö®

**Ligne 256**:
```python
return provider.list_symbols(limit=10)  # ‚ùå Param√®tre invalide
```

**Solution**:
```python
# Option 1: Limiter apr√®s r√©cup√©ration
symbols = provider.list_symbols()
return symbols[:10]  # ‚úÖ Simple

# Option 2: Ajouter param√®tre limit √† la m√©thode
def list_symbols(self, group: Optional[str] = None, limit: Optional[int] = None):
    symbols = self.config.groups.get(group, []) if group else self.config.symbols
    return symbols[:limit] if limit else symbols  # ‚úÖ Flexible
```

**Recommandation**: **Option 1** (limiter apr√®s)
- Plus simple, pas de modification API
- Suffisant pour le cas d'usage

---

### 4. Type Corr√©lation List[int] ‚Üí List[float] ‚ö†Ô∏è

**Ligne 329**:
```python
avg_correlations: List[int] = []  # ‚ùå Type incorrect
```

**Solution triviale**:
```python
avg_correlations: List[float] = []  # ‚úÖ Type correct
```

---

## üìä √âtat Actuel des Erreurs

### Fichier diversity_pipeline.py

| Cat√©gorie              | Count | √âtat                     |
| ---------------------- | ----- | ------------------------ |
| **Erreurs critiques**  | 4     | üîÑ 1 r√©solue, 3 restantes |
| **Erreurs mineures**   | 1     | ‚ùå Non r√©solue            |
| **Warnings formatage** | 15    | ‚ùå Non r√©solus            |
| **TOTAL**              | 20    | üîÑ **En cours**           |

### D√©tail Erreurs Critiques Restantes

1. ‚ùå `bank.compute_batch()` n'existe pas (ligne 170)
2. ‚ùå `td_config.cache_dir` n'existe pas (ligne 197)
3. ‚ùå `list_symbols(limit=10)` param√®tre invalide (ligne 256)
4. ‚ö†Ô∏è Type `List[int]` vs `List[float]` (ligne 329)

---

## üöÄ Plan d'Action Recommand√©

### Prochaine Session (1-2h)

#### √âtape 1 : Cr√©er compute_batch() dans IndicatorBank (30 min)

**Fichier**: `src/threadx/indicators/bank.py`

**Code √† ajouter**:
```python
def compute_batch(
    self,
    data: pd.DataFrame,
    indicators: List[str],
    symbol: str = "",
    timeframe: str = ""
) -> pd.DataFrame:
    """
    Calcule plusieurs indicateurs et retourne DataFrame enrichi.
    
    Args:
        data: DataFrame OHLCV
        indicators: Liste format "type_period" ex: ["rsi_14", "bb_20"]
        symbol, timeframe: M√©tadonn√©es pour cache
    
    Returns:
        DataFrame avec colonnes d'indicateurs ajout√©es
    
    Example:
        >>> bank = IndicatorBank()
        >>> df_with_ind = bank.compute_batch(
        ...     ohlcv_df,
        ...     indicators=["rsi_14", "bb_20_2.0", "sma_50"]
        ... )
        >>> print(df_with_ind.columns)
        ['open', 'high', 'low', 'close', 'volume', 
         'rsi_14', 'bb_upper_20', 'bb_middle_20', 'bb_lower_20', 'sma_50']
    """
    result_df = data.copy()
    
    for indicator_str in indicators:
        # Parse format "type_param1_param2..."
        parts = indicator_str.split("_")
        ind_type = parts[0]
        
        # Parser selon type
        if ind_type == "rsi":
            period = int(parts[1]) if len(parts) > 1 else 14
            params = {"period": period}
            rsi_result = self.batch_ensure(ind_type, [params], data, symbol, timeframe)
            result_df[f"rsi_{period}"] = list(rsi_result.values())[0]
        
        elif ind_type == "bb":
            period = int(parts[1]) if len(parts) > 1 else 20
            std = float(parts[2]) if len(parts) > 2 else 2.0
            params = {"period": period, "std_dev": std}
            bb_result = self.batch_ensure(ind_type, [params], data, symbol, timeframe)
            upper, middle, lower = list(bb_result.values())[0]
            result_df[f"bb_upper_{period}"] = upper
            result_df[f"bb_middle_{period}"] = middle
            result_df[f"bb_lower_{period}"] = lower
        
        # Ajouter autres indicateurs (sma, ema, macd, atr...)
    
    return result_df
```

#### √âtape 2 : Ajouter cache_dir √† TokenDiversityConfig (5 min)

**Fichier**: `src/threadx/data/providers/token_diversity.py`

```python
@dataclass(frozen=True)
class TokenDiversityConfig:
    groups: Mapping[str, List[str]]
    symbols: List[str]
    supported_tf: Tuple[str, ...] = ("1m", "5m", "15m", "1h", "4h", "1d")
    cache_dir: str = "./data/diversity_cache"  # ‚úÖ Ajout√©
```

#### √âtape 3 : Corrections finales diversity_pipeline.py (15 min)

1. Corriger `list_symbols(limit=10)` ‚Üí `list_symbols()[:10]`
2. Corriger `List[int]` ‚Üí `List[float]`
3. Formatter avec Black (optionnel)

#### √âtape 4 : Tests de validation (30 min)

```python
# test_token_diversity.py
def test_token_provider():
    config = create_default_config()
    provider = TokenDiversityDataSource(config)
    
    # Test list_symbols
    assert len(provider.list_symbols()) > 0
    assert "BTCUSDT" in provider.list_symbols("L1")
    
    # Test fetch_ohlcv (NotImplementedError attendu)
    with pytest.raises(NotImplementedError):
        provider.fetch_ohlcv("BTCUSDT", "1h")

def test_diversity_pipeline():
    # Test avec donn√©es mock√©es
    ...
```

---

## üí° D√©cision Requise

Pour continuer le d√©bogage, j'ai besoin de votre choix :

### Option 1 : Impl√©menter compute_batch() (Recommand√©) ‚≠ê
- **Dur√©e**: 30-45 min
- **Avantages**: API propre, r√©utilisable
- **Inconv√©nient**: Modification IndicatorBank

### Option 2 : Adapter diversity_pipeline.py √† batch_ensure()
- **Dur√©e**: 20-30 min
- **Avantages**: Pas de modification IndicatorBank
- **Inconv√©nient**: Code moins lisible

### Option 3 : Reporter IndicatorBank, finir autres corrections
- **Dur√©e**: 10 min
- **Avantages**: R√©solution rapide 3 autres erreurs
- **Inconv√©nient**: diversity_pipeline.py reste cass√©

**Que pr√©f√©rez-vous ?**

---

**Auteur**: GitHub Copilot  
**Date**: 10 octobre 2025  
**Temps √©coul√©**: 30 minutes  
**Progr√®s**: 40% (1/2 fichiers complets)
