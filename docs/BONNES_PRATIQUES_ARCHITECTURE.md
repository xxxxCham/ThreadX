# Guide des Bonnes Pratiques - Architecture ThreadX
**Date**: 11 octobre 2025  
**Version**: 1.0  
**Objectif**: Structure professionnelle et maintenable

---

## üìê Architecture Recommand√©e

### Structure de R√©pertoires Id√©ale

```
ThreadX/
‚îú‚îÄ‚îÄ .github/                      # CI/CD & GitHub configs
‚îÇ   ‚îú‚îÄ‚îÄ workflows/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ci.yml               # Tests automatiques
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ release.yml          # Publication releases
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lint.yml             # V√©rification code quality
‚îÇ   ‚îî‚îÄ‚îÄ ISSUE_TEMPLATE/          # Templates issues
‚îÇ
‚îú‚îÄ‚îÄ src/threadx/                 # Code source principal (PEP 420)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config/                  # Configuration centralis√©e
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ settings.py          # Classe Settings (Pydantic)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ paths.py             # Gestion chemins
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ data/                    # Pipeline donn√©es
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ providers/           # Sources de donn√©es
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py          # Interface abstraite
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ binance.py       # Provider Binance
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ token_diversity.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ingest.py            # Ingestion manager
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ io.py                # I/O Parquet/JSON
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ registry.py          # M√©tadonn√©es
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ indicators/              # Indicateurs techniques
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ numpy.py             # ‚úÖ Cr√©√© (optimisations NumPy)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bank.py              # Cache & registry
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ custom/              # Indicateurs personnalis√©s
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ backtest/                # Moteur backtesting
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ engine.py            # BacktestEngine
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ strategy.py          # Strat√©gies base
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ results.py           # Analyse r√©sultats
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ ui/                      # Interfaces utilisateur
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_manager.py      # ‚úÖ Existe (Tkinter)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cli.py               # Interface CLI
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dashboard.py         # Streamlit dashboard
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ utils/                   # Utilitaires
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logging_utils.py     # Configuration logging
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ performance.py       # Profiling
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ validators.py        # Validation donn√©es
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ models/                  # Mod√®les de donn√©es (Pydantic)
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ ohlcv.py             # Mod√®le OHLCV
‚îÇ       ‚îî‚îÄ‚îÄ backtest.py          # R√©sultats backtest
‚îÇ
‚îú‚îÄ‚îÄ tests/                       # Tests unitaires & int√©gration
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py              # Fixtures pytest
‚îÇ   ‚îú‚îÄ‚îÄ unit/                    # Tests unitaires
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_indicators.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_data_providers.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_backtest.py
‚îÇ   ‚îú‚îÄ‚îÄ integration/             # Tests int√©gration
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_pipeline.py
‚îÇ   ‚îî‚îÄ‚îÄ fixtures/                # Donn√©es de test
‚îÇ       ‚îî‚îÄ‚îÄ sample_ohlcv.parquet
‚îÇ
‚îú‚îÄ‚îÄ docs/                        # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ index.md                 # Page d'accueil
‚îÇ   ‚îú‚îÄ‚îÄ api/                     # Documentation API
‚îÇ   ‚îú‚îÄ‚îÄ tutorials/               # Tutoriels
‚îÇ   ‚îî‚îÄ‚îÄ architecture/            # Diagrammes
‚îÇ
‚îú‚îÄ‚îÄ scripts/                     # Scripts utilitaires
‚îÇ   ‚îú‚îÄ‚îÄ download_data.py         # T√©l√©chargement donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ compute_indicators.py    # Calcul batch indicateurs
‚îÇ   ‚îî‚îÄ‚îÄ benchmark.py             # Performance tests
‚îÇ
‚îú‚îÄ‚îÄ configs/                     # Fichiers configuration
‚îÇ   ‚îú‚îÄ‚îÄ default.toml             # Config par d√©faut
‚îÇ   ‚îú‚îÄ‚îÄ development.toml         # Dev environment
‚îÇ   ‚îú‚îÄ‚îÄ production.toml          # Production
‚îÇ   ‚îî‚îÄ‚îÄ paths.toml               # Chemins TradXPro
‚îÇ
‚îú‚îÄ‚îÄ data/                        # Donn√©es (gitignored)
‚îÇ   ‚îú‚îÄ‚îÄ raw/                     # Donn√©es brutes
‚îÇ   ‚îú‚îÄ‚îÄ processed/               # Donn√©es trait√©es
‚îÇ   ‚îú‚îÄ‚îÄ indicators/              # Cache indicateurs
‚îÇ   ‚îî‚îÄ‚îÄ backtest_results/        # R√©sultats backtests
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                   # Jupyter notebooks
‚îÇ   ‚îú‚îÄ‚îÄ exploratory/             # Analyse exploratoire
‚îÇ   ‚îî‚îÄ‚îÄ examples/                # Exemples d'utilisation
‚îÇ
‚îú‚îÄ‚îÄ docker/                      # Conteneurisation
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml
‚îÇ   ‚îî‚îÄ‚îÄ .dockerignore
‚îÇ
‚îú‚îÄ‚îÄ .venv/                       # Virtual environment (gitignored)
‚îÇ
‚îú‚îÄ‚îÄ pyproject.toml               # ‚úÖ Configuration projet moderne
‚îú‚îÄ‚îÄ setup.py                     # Installation (fallback)
‚îú‚îÄ‚îÄ requirements.txt             # D√©pendances production
‚îú‚îÄ‚îÄ requirements-dev.txt         # D√©pendances d√©veloppement
‚îú‚îÄ‚îÄ .pre-commit-config.yaml      # Pre-commit hooks
‚îú‚îÄ‚îÄ .gitignore                   # Git ignore
‚îú‚îÄ‚îÄ .env.example                 # Variables d'environnement template
‚îú‚îÄ‚îÄ README.md                    # Documentation principale
‚îú‚îÄ‚îÄ CHANGELOG.md                 # Historique changements
‚îú‚îÄ‚îÄ LICENSE                      # Licence
‚îî‚îÄ‚îÄ Makefile                     # Commandes utilitaires
```

---

## üéØ Bonnes Pratiques Appliqu√©es

### 1. **Configuration Centralis√©e (TOML + Pydantic)**

#### ‚ùå Mauvaise Pratique (Ancien Code)
```python
# Variables globales √©parpill√©es
JSON_ROOT = r"D:\TradXPro\crypto_data_json"
PARQUET_ROOT = r"D:\TradXPro\crypto_data_parquet"
HISTORY_DAYS = 365
BINANCE_LIMIT = 1000
```

#### ‚úÖ Bonne Pratique
```python
# configs/default.toml
[paths]
json_root = "data/raw/json"
parquet_root = "data/processed/parquet"
indicators_db = "data/indicators"

[data]
history_days = 365
binance_limit = 1000
supported_timeframes = ["1m", "3m", "5m", "15m", "30m", "1h", "4h", "1d"]

[indicators]
default_rsi_period = 14
default_bb_period = 20
default_bb_std = 2.0

# src/threadx/config/settings.py
from pathlib import Path
from typing import List
from pydantic import BaseSettings, Field

class PathsConfig(BaseSettings):
    json_root: Path = Field(default=Path("data/raw/json"))
    parquet_root: Path = Field(default=Path("data/processed/parquet"))
    indicators_db: Path = Field(default=Path("data/indicators"))
    
    class Config:
        env_prefix = "THREADX_"  # Variables d'environnement

class DataConfig(BaseSettings):
    history_days: int = Field(default=365, ge=1, le=3650)
    binance_limit: int = Field(default=1000, ge=1, le=1000)
    supported_timeframes: List[str] = ["1m", "3m", "5m", "15m", "30m", "1h"]

class Settings(BaseSettings):
    paths: PathsConfig = PathsConfig()
    data: DataConfig = DataConfig()
    
    @classmethod
    def load_from_toml(cls, config_file: Path) -> "Settings":
        """Charge depuis fichier TOML."""
        import toml
        config = toml.load(config_file)
        return cls(**config)

# Usage
from threadx.config import Settings

settings = Settings.load_from_toml(Path("configs/default.toml"))
print(settings.data.history_days)  # Type-safe!
```

---

### 2. **Dependency Injection (Pas de Singletons)**

#### ‚ùå Mauvaise Pratique
```python
# Singleton global (couplage fort)
class IndicatorBank:
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

# Utilisation coupl√©e
bank = IndicatorBank()  # Toujours la m√™me instance
```

#### ‚úÖ Bonne Pratique
```python
# Injection de d√©pendances
from abc import ABC, abstractmethod
from typing import Protocol

class IndicatorProvider(Protocol):
    """Interface pour fournisseurs d'indicateurs."""
    def calculate_rsi(self, close: np.ndarray, period: int) -> np.ndarray:
        ...

class NumPyIndicatorProvider:
    """Impl√©mentation NumPy optimis√©e."""
    def calculate_rsi(self, close: np.ndarray, period: int) -> np.ndarray:
        return rsi_np(close, period)

class BacktestEngine:
    """Moteur backtest avec injection de d√©pendances."""
    
    def __init__(
        self,
        indicator_provider: IndicatorProvider,
        settings: Settings
    ):
        self.indicators = indicator_provider
        self.settings = settings
    
    def run(self, df: pd.DataFrame) -> BacktestResult:
        # Utilise l'interface, pas l'impl√©mentation
        rsi = self.indicators.calculate_rsi(
            df['close'].values,
            self.settings.indicators.default_rsi_period
        )

# Usage (testable et flexible)
provider = NumPyIndicatorProvider()
engine = BacktestEngine(
    indicator_provider=provider,
    settings=settings
)
```

---

### 3. **Type Hints & Validation (Pydantic)**

#### ‚ùå Mauvaise Pratique
```python
def calculate_indicators(df, indicators):
    """Calcule indicateurs (pas de type hints)."""
    results = {}
    for ind in indicators:
        if ind == "rsi":
            results[ind] = calc_rsi(df)
    return results
```

#### ‚úÖ Bonne Pratique
```python
from typing import List, Dict, Optional
from pydantic import BaseModel, validator
import pandas as pd

class OHLCVFrame(BaseModel):
    """Mod√®le valid√© pour DataFrame OHLCV."""
    data: pd.DataFrame
    symbol: str
    timeframe: str
    
    class Config:
        arbitrary_types_allowed = True
    
    @validator('data')
    def validate_ohlcv_columns(cls, df):
        required = {'open', 'high', 'low', 'close', 'volume'}
        missing = required - set(df.columns)
        if missing:
            raise ValueError(f"Colonnes manquantes: {missing}")
        return df
    
    @validator('timeframe')
    def validate_timeframe(cls, tf):
        valid = {'1m', '3m', '5m', '15m', '30m', '1h', '4h', '1d'}
        if tf not in valid:
            raise ValueError(f"Timeframe invalide: {tf}")
        return tf

class IndicatorRequest(BaseModel):
    """Requ√™te de calcul d'indicateurs."""
    ohlcv: OHLCVFrame
    indicators: List[str]
    params: Optional[Dict[str, int]] = None

class IndicatorResponse(BaseModel):
    """R√©ponse avec indicateurs calcul√©s."""
    data: pd.DataFrame
    computed: List[str]
    errors: List[str] = []
    
    class Config:
        arbitrary_types_allowed = True

def calculate_indicators(
    request: IndicatorRequest
) -> IndicatorResponse:
    """
    Calcule indicateurs avec validation Pydantic.
    
    Args:
        request: Requ√™te valid√©e
    
    Returns:
        R√©ponse avec donn√©es enrichies
    
    Raises:
        ValidationError: Si donn√©es invalides
    """
    df = request.ohlcv.data.copy()
    computed = []
    errors = []
    
    for indicator in request.indicators:
        try:
            if indicator == "rsi":
                period = request.params.get("rsi_period", 14) if request.params else 14
                df["rsi"] = rsi_np(df["close"].values, period)
                computed.append("rsi")
        except Exception as e:
            errors.append(f"Erreur {indicator}: {str(e)}")
    
    return IndicatorResponse(
        data=df,
        computed=computed,
        errors=errors
    )

# Usage (type-safe et valid√©)
ohlcv = OHLCVFrame(data=df, symbol="BTCUSDT", timeframe="1h")
request = IndicatorRequest(
    ohlcv=ohlcv,
    indicators=["rsi", "macd"],
    params={"rsi_period": 21}
)
response = calculate_indicators(request)  # ‚úÖ Valid√© automatiquement
```

---

### 4. **Logging Structur√© (pas de print)**

#### ‚ùå Mauvaise Pratique
```python
def download_data(symbol):
    print(f"T√©l√©chargement {symbol}...")
    try:
        data = fetch_klines(symbol)
        print(f"Succ√®s: {len(data)} bougies")
    except Exception as e:
        print(f"ERREUR: {e}")
```

#### ‚úÖ Bonne Pratique
```python
# src/threadx/utils/logging_utils.py
import logging
import logging.config
from pathlib import Path
from typing import Optional

def setup_logging(
    log_level: str = "INFO",
    log_file: Optional[Path] = None,
    json_logs: bool = False
) -> logging.Logger:
    """
    Configure le syst√®me de logging ThreadX.
    
    Args:
        log_level: Niveau de log (DEBUG, INFO, WARNING, ERROR)
        log_file: Fichier de log optionnel
        json_logs: Format JSON pour parsing facile
    
    Returns:
        Logger configur√©
    """
    import logging.handlers
    
    config = {
        "version": 1,
        "disable_existing_loggers": False,
        "formatters": {
            "standard": {
                "format": "%(asctime)s [%(levelname)s] %(name)s: %(message)s",
                "datefmt": "%Y-%m-%d %H:%M:%S"
            },
            "json": {
                "()": "pythonjsonlogger.jsonlogger.JsonFormatter",
                "format": "%(asctime)s %(name)s %(levelname)s %(message)s"
            }
        },
        "handlers": {
            "console": {
                "class": "logging.StreamHandler",
                "formatter": "json" if json_logs else "standard",
                "stream": "ext://sys.stdout"
            }
        },
        "root": {
            "level": log_level,
            "handlers": ["console"]
        }
    }
    
    if log_file:
        config["handlers"]["file"] = {
            "class": "logging.handlers.RotatingFileHandler",
            "filename": str(log_file),
            "maxBytes": 10485760,  # 10MB
            "backupCount": 5,
            "formatter": "json" if json_logs else "standard"
        }
        config["root"]["handlers"].append("file")
    
    logging.config.dictConfig(config)
    return logging.getLogger("threadx")

# Usage dans modules
import logging
from threadx.utils.logging_utils import setup_logging

logger = logging.getLogger(__name__)

def download_data(symbol: str) -> List[Dict]:
    """T√©l√©charge donn√©es avec logging structur√©."""
    logger.info("download_started", extra={
        "symbol": symbol,
        "source": "binance"
    })
    
    try:
        data = fetch_klines(symbol)
        logger.info("download_success", extra={
            "symbol": symbol,
            "candles_count": len(data),
            "duration_ms": 1234
        })
        return data
    
    except Exception as e:
        logger.error("download_failed", extra={
            "symbol": symbol,
            "error": str(e),
            "error_type": type(e).__name__
        }, exc_info=True)
        raise
```

---

### 5. **Testing Complet (pytest + fixtures)**

#### Structure Tests
```
tests/
‚îú‚îÄ‚îÄ conftest.py              # Fixtures globales
‚îú‚îÄ‚îÄ unit/                    # Tests unitaires isol√©s
‚îÇ   ‚îú‚îÄ‚îÄ test_indicators.py
‚îÇ   ‚îî‚îÄ‚îÄ test_validators.py
‚îú‚îÄ‚îÄ integration/             # Tests bout-en-bout
‚îÇ   ‚îî‚îÄ‚îÄ test_pipeline.py
‚îî‚îÄ‚îÄ fixtures/                # Donn√©es de test
    ‚îî‚îÄ‚îÄ sample_data.parquet
```

#### ‚úÖ Bonnes Pratiques Tests
```python
# tests/conftest.py
import pytest
import pandas as pd
import numpy as np
from pathlib import Path

@pytest.fixture
def sample_ohlcv() -> pd.DataFrame:
    """Fixture DataFrame OHLCV r√©aliste."""
    np.random.seed(42)
    n = 1000
    
    dates = pd.date_range("2024-01-01", periods=n, freq="1h", tz="UTC")
    close = 50000 + np.cumsum(np.random.randn(n) * 100)
    high = close + np.abs(np.random.randn(n) * 50)
    low = close - np.abs(np.random.randn(n) * 50)
    open_price = np.roll(close, 1)
    volume = np.random.randint(1000, 10000, n)
    
    return pd.DataFrame({
        'open': open_price,
        'high': high,
        'low': low,
        'close': close,
        'volume': volume
    }, index=dates)

@pytest.fixture
def mock_settings() -> Settings:
    """Settings de test."""
    return Settings(
        data=DataConfig(history_days=30, binance_limit=500),
        paths=PathsConfig(json_root=Path("/tmp/test"))
    )

# tests/unit/test_indicators.py
import pytest
import numpy as np
from threadx.indicators.numpy import rsi_np, boll_np

class TestRSI:
    """Tests unitaires RSI."""
    
    def test_rsi_basic(self, sample_ohlcv):
        """Test calcul RSI basique."""
        rsi = rsi_np(sample_ohlcv['close'].values, period=14)
        
        assert len(rsi) == len(sample_ohlcv)
        assert np.all((rsi >= 0) & (rsi <= 100))
        assert not np.all(np.isnan(rsi))
    
    def test_rsi_extreme_values(self):
        """Test RSI sur valeurs extr√™mes."""
        # Prix constants ‚Üí RSI = 50
        close_flat = np.ones(100) * 100
        rsi = rsi_np(close_flat, period=14)
        np.testing.assert_allclose(rsi[14:], 50.0, atol=1e-6)
        
        # Prix haussiers ‚Üí RSI proche 100
        close_up = np.arange(100) * 10
        rsi = rsi_np(close_up, period=14)
        assert rsi[-1] > 80
    
    @pytest.mark.parametrize("period", [7, 14, 21, 50])
    def test_rsi_different_periods(self, sample_ohlcv, period):
        """Test RSI avec diff√©rentes p√©riodes."""
        rsi = rsi_np(sample_ohlcv['close'].values, period=period)
        
        assert len(rsi) == len(sample_ohlcv)
        assert np.all((rsi >= 0) & (rsi <= 100))
    
    def test_rsi_empty_input(self):
        """Test RSI sur input vide."""
        rsi = rsi_np(np.array([]), period=14)
        assert len(rsi) == 0

class TestBollingerBands:
    """Tests unitaires Bollinger Bands."""
    
    def test_bollinger_basic(self, sample_ohlcv):
        """Test calcul Bollinger basique."""
        lower, middle, upper, z = boll_np(
            sample_ohlcv['close'].values,
            period=20,
            std=2.0
        )
        
        assert len(lower) == len(sample_ohlcv)
        assert np.all(lower <= middle)
        assert np.all(middle <= upper)
    
    def test_bollinger_zscore_range(self, sample_ohlcv):
        """Test z-score dans plage raisonnable."""
        _, _, _, z = boll_np(sample_ohlcv['close'].values, 20, 2.0)
        
        # 95% des valeurs doivent √™tre entre -2 et +2 (2 std)
        within_range = np.sum(np.abs(z) <= 2)
        percentage = within_range / len(z)
        assert percentage > 0.90  # Au moins 90%

# tests/integration/test_pipeline.py
import pytest
from threadx.data.ingest import IngestionManager
from threadx.indicators.numpy import add_all_indicators

@pytest.mark.integration
def test_full_pipeline(mock_settings, tmp_path):
    """Test pipeline complet end-to-end."""
    # 1. Ingestion
    manager = IngestionManager(mock_settings)
    # ... (mock Binance API)
    
    # 2. Calcul indicateurs
    df = load_ohlcv("BTCUSDT", "1h")
    df_enriched = add_all_indicators(df)
    
    # 3. Backtest
    # ...
    
    assert "rsi" in df_enriched.columns
    assert "macd" in df_enriched.columns
```

---

### 6. **CI/CD avec GitHub Actions**

#### ‚úÖ Workflow Complet
```yaml
# .github/workflows/ci.yml
name: CI Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install ruff mypy black isort
      
      - name: Ruff (linter)
        run: ruff check src/
      
      - name: Black (formatter)
        run: black --check src/
      
      - name: isort (imports)
        run: isort --check-only src/
      
      - name: mypy (type checker)
        run: mypy src/

  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.10', '3.11', '3.12']
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
      
      - name: Install dependencies
        run: |
          pip install -e ".[dev]"
      
      - name: Run tests with coverage
        run: |
          pytest tests/ \
            --cov=src/threadx \
            --cov-report=xml \
            --cov-report=html \
            --cov-fail-under=80
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml

  build:
    needs: [lint, test]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Build package
        run: |
          pip install build
          python -m build
      
      - name: Check package
        run: |
          pip install twine
          twine check dist/*
```

---

### 7. **Pre-commit Hooks (Qualit√© Automatique)**

```yaml
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files
        args: ['--maxkb=5000']
      - id: check-json
      - id: check-toml
  
  - repo: https://github.com/psf/black
    rev: 23.12.1
    hooks:
      - id: black
        language_version: python3.11
  
  - repo: https://github.com/pycqa/isort
    rev: 5.13.2
    hooks:
      - id: isort
        args: ["--profile", "black"]
  
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.1.11
    hooks:
      - id: ruff
        args: [--fix, --exit-non-zero-on-fix]
  
  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.8.0
    hooks:
      - id: mypy
        additional_dependencies: [types-all]
        args: [--strict, --ignore-missing-imports]

# Installation
# pip install pre-commit
# pre-commit install
```

---

### 8. **pyproject.toml Moderne (PEP 621)**

```toml
# pyproject.toml
[build-system]
requires = ["setuptools>=65.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "threadx"
version = "2.0.0"
description = "Framework de trading crypto haute performance"
readme = "README.md"
requires-python = ">=3.10"
license = {text = "MIT"}
authors = [
    {name = "ThreadX Team", email = "team@threadx.dev"}
]
keywords = ["trading", "crypto", "backtest", "indicators", "binance"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Financial and Insurance Industry",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Office/Business :: Financial :: Investment",
]

dependencies = [
    "numpy>=1.24.0",
    "pandas>=2.0.0",
    "pyarrow>=14.0.0",
    "pydantic>=2.0.0",
    "requests>=2.31.0",
    "toml>=0.10.2",
    "tqdm>=4.66.0",
    "python-dotenv>=1.0.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
    "pytest-cov>=4.1.0",
    "pytest-asyncio>=0.21.0",
    "pytest-mock>=3.12.0",
    "ruff>=0.1.0",
    "black>=23.12.0",
    "isort>=5.13.0",
    "mypy>=1.8.0",
    "pre-commit>=3.6.0",
]
ui = [
    "streamlit>=1.29.0",
    "plotly>=5.18.0",
]
docs = [
    "sphinx>=7.2.0",
    "sphinx-rtd-theme>=2.0.0",
    "myst-parser>=2.0.0",
]

[project.scripts]
threadx = "threadx.cli:main"
threadx-download = "threadx.scripts.download_data:main"
threadx-backtest = "threadx.backtest.cli:main"

[project.urls]
Homepage = "https://github.com/threadx/threadx"
Documentation = "https://threadx.readthedocs.io"
Repository = "https://github.com/threadx/threadx"
Changelog = "https://github.com/threadx/threadx/blob/main/CHANGELOG.md"

[tool.setuptools.packages.find]
where = ["src"]

[tool.setuptools.package-data]
threadx = ["py.typed", "configs/*.toml"]

# Configuration Ruff (linter moderne)
[tool.ruff]
line-length = 100
target-version = "py310"
src = ["src", "tests"]

select = [
    "E",   # pycodestyle errors
    "W",   # pycodestyle warnings
    "F",   # pyflakes
    "I",   # isort
    "N",   # pep8-naming
    "UP",  # pyupgrade
    "B",   # flake8-bugbear
    "C4",  # flake8-comprehensions
    "SIM", # flake8-simplify
]

ignore = [
    "E501",  # line too long (g√©r√© par black)
    "B008",  # function call in argument defaults
]

[tool.ruff.per-file-ignores]
"__init__.py" = ["F401"]  # unused imports OK
"tests/*" = ["S101"]      # assert OK in tests

# Configuration Black (formatter)
[tool.black]
line-length = 100
target-version = ['py310', 'py311', 'py312']
include = '\.pyi?$'
extend-exclude = '''
/(
    \.git
  | \.venv
  | build
  | dist
)/
'''

# Configuration isort (tri imports)
[tool.isort]
profile = "black"
line_length = 100
skip_gitignore = true
known_first_party = ["threadx"]

# Configuration mypy (type checker)
[tool.mypy]
python_version = "3.10"
strict = true
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
ignore_missing_imports = true

[[tool.mypy.overrides]]
module = "tests.*"
disallow_untyped_defs = false

# Configuration pytest
[tool.pytest.ini_options]
minversion = "7.0"
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = [
    "--strict-markers",
    "--strict-config",
    "--cov=src/threadx",
    "--cov-report=term-missing:skip-covered",
    "--cov-report=html",
    "--cov-report=xml",
]
markers = [
    "unit: Unit tests",
    "integration: Integration tests",
    "slow: Slow tests (deselect with '-m \"not slow\"')",
]

# Configuration coverage
[tool.coverage.run]
source = ["src/threadx"]
omit = [
    "*/tests/*",
    "*/__pycache__/*",
    "*/site-packages/*",
]

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "raise AssertionError",
    "raise NotImplementedError",
    "if __name__ == .__main__.:",
    "if TYPE_CHECKING:",
    "@abstractmethod",
]
```

---

### 9. **Documentation (Sphinx + ReadTheDocs)**

```python
# docs/conf.py
project = 'ThreadX'
copyright = '2025, ThreadX Team'
author = 'ThreadX Team'
release = '2.0.0'

extensions = [
    'sphinx.ext.autodoc',
    'sphinx.ext.napoleon',  # Google/NumPy docstrings
    'sphinx.ext.viewcode',
    'sphinx.ext.intersphinx',
    'myst_parser',  # Markdown support
]

# Google-style docstrings
napoleon_google_docstring = True
napoleon_numpy_docstring = False

# Auto-documentation
autodoc_default_options = {
    'members': True,
    'undoc-members': True,
    'private-members': False,
    'show-inheritance': True,
}

html_theme = 'sphinx_rtd_theme'
```

---

### 10. **Makefile (Commandes Utilitaires)**

```makefile
# Makefile
.PHONY: help install test lint format clean docs build

help:  ## Affiche l'aide
	@grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-20s\033[0m %s\n", $$1, $$2}'

install:  ## Installe le projet en mode d√©veloppement
	pip install -e ".[dev]"
	pre-commit install

test:  ## Lance les tests avec coverage
	pytest tests/ --cov=src/threadx --cov-report=html --cov-report=term

test-fast:  ## Tests rapides (skip slow)
	pytest tests/ -m "not slow" -v

lint:  ## V√©rification qualit√© code
	ruff check src/ tests/
	black --check src/ tests/
	isort --check-only src/ tests/
	mypy src/

format:  ## Formate le code automatiquement
	black src/ tests/
	isort src/ tests/
	ruff check src/ tests/ --fix

clean:  ## Nettoie les fichiers temporaires
	find . -type d -name "__pycache__" -exec rm -rf {} +
	find . -type d -name "*.egg-info" -exec rm -rf {} +
	find . -type d -name ".pytest_cache" -exec rm -rf {} +
	find . -type d -name ".ruff_cache" -exec rm -rf {} +
	find . -type d -name ".mypy_cache" -exec rm -rf {} +
	rm -rf build/ dist/ htmlcov/ .coverage coverage.xml

docs:  ## G√©n√®re la documentation
	cd docs && make html

build:  ## Build le package
	python -m build

publish-test:  ## Publie sur TestPyPI
	twine upload --repository testpypi dist/*

publish:  ## Publie sur PyPI
	twine upload dist/*

docker-build:  ## Build image Docker
	docker build -t threadx:latest -f docker/Dockerfile .

docker-run:  ## Lance container Docker
	docker-compose -f docker/docker-compose.yml up

benchmark:  ## Lance les benchmarks performance
	python scripts/benchmark.py

download-data:  ## T√©l√©charge donn√©es crypto
	python scripts/download_data.py --symbols BTCUSDT ETHUSDT --timeframes 1h 4h

.DEFAULT_GOAL := help
```

---

## üöÄ Plan de Migration vers Bonnes Pratiques

### Phase 1: Fondations (Semaine 1-2)

- [ ] Cr√©er `pyproject.toml` moderne
- [ ] Configurer pre-commit hooks
- [ ] Setup CI/CD GitHub Actions
- [ ] Cr√©er structure tests/ avec fixtures
- [ ] Ajouter type hints progressivement

### Phase 2: Architecture (Semaine 3-4)

- [ ] Cr√©er `Settings` avec Pydantic
- [ ] Refactorer chemins (configs/paths.toml)
- [ ] Impl√©menter dependency injection
- [ ] Migrer vers logging structur√©
- [ ] S√©parer concerns (data/indicators/backtest)

### Phase 3: Qualit√© (Semaine 5-6)

- [ ] Atteindre 80%+ coverage tests
- [ ] Documentation Sphinx compl√®te
- [ ] Performance profiling
- [ ] Docker images
- [ ] Release automatis√©e

---

## üìä Checklist Qualit√©

### Code Quality
- [ ] Type hints sur toutes fonctions publiques
- [ ] Docstrings Google-style
- [ ] Pas de print() (logging uniquement)
- [ ] Pas de variables globales
- [ ] S√©paration config/code
- [ ] Dependency injection

### Tests
- [ ] Coverage > 80%
- [ ] Tests unitaires isol√©s
- [ ] Tests int√©gration end-to-end
- [ ] Fixtures r√©utilisables
- [ ] Mocks pour APIs externes

### Documentation
- [ ] README.md complet
- [ ] CHANGELOG.md √† jour
- [ ] API docs g√©n√©r√©e (Sphinx)
- [ ] Exemples d'utilisation
- [ ] Architecture diagrammes

### DevOps
- [ ] CI/CD fonctionnel
- [ ] Pre-commit hooks
- [ ] Release automatique
- [ ] Docker images
- [ ] Monitoring performance

---

**Cr√©√© le**: 11 octobre 2025  
**Auteur**: GitHub Copilot (ThreadX Core Team)  
**Statut**: Guide de R√©f√©rence
